#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT-SoVITS è®­ç»ƒAPI - å¢å¼ºç‰ˆ
åŸºäºç”¨æˆ·åˆ†æçš„è¿›é˜¶æ€è·¯ï¼Œèå…¥éŸ³è‰²å…‹éš†ä¼˜åŒ–ã€å¤šæ¨¡å‹èåˆã€éŸ³é¢‘å¢å¼ºç­‰ç‰¹æ€§
"""

import os
import sys
import json
import yaml
import shutil
import logging
import subprocess
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import zipfile
import time
import requests
from concurrent.futures import ThreadPoolExecutor
import librosa
import soundfile as sf
from tqdm import tqdm
import threading

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gpt_sovits_training.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TrainingProgressMonitor:
    """è®­ç»ƒè¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self, total_steps: int):
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = time.time()
        self.step_times = []
        
    def update(self, step_name: str, step_description: str = ""):
        """æ›´æ–°è¿›åº¦"""
        self.current_step += 1
        elapsed_time = time.time() - self.start_time
        self.step_times.append(elapsed_time)
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        progress = (self.current_step / self.total_steps) * 100
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        if self.current_step > 1:
            avg_time_per_step = elapsed_time / self.current_step
            remaining_steps = self.total_steps - self.current_step
            estimated_remaining = avg_time_per_step * remaining_steps
            eta_str = f"é¢„è®¡å‰©ä½™æ—¶é—´: {self._format_time(estimated_remaining)}"
        else:
            eta_str = "è®¡ç®—ä¸­..."
        
        logger.info(f"=== è®­ç»ƒè¿›åº¦ [{self.current_step}/{self.total_steps}] ({progress:.1f}%) ===")
        logger.info(f"å½“å‰æ­¥éª¤: {step_name}")
        if step_description:
            logger.info(f"æ­¥éª¤æè¿°: {step_description}")
        logger.info(f"å·²ç”¨æ—¶é—´: {self._format_time(elapsed_time)}")
        logger.info(f"{eta_str}")
        logger.info("=" * 50)
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ{secs}ç§’"
        elif minutes > 0:
            return f"{minutes}åˆ†é’Ÿ{secs}ç§’"
        else:
            return f"{secs}ç§’"

class GPTSoVITSTrainingAPI:
    """GPT-SoVITSè®­ç»ƒAPI - å¢å¼ºç‰ˆ"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–è®­ç»ƒAPI"""
        self.config = self._load_config(config_path)
        self.base_dir = Path.cwd()
        self.gpt_sovits_dir = self.base_dir / "GPT-SoVITS"
        self.audio_dir = self.base_dir / "audio_files"
        self.result_dir = self.base_dir / "result"
        self.temp_dir = self.base_dir / "temp_training"
        
        # è¿›é˜¶é…ç½®
        self.enhancement_config = {
            "audio_augmentation": True,  # éŸ³é¢‘å¢å¼º
            "multi_model_ensemble": True,  # å¤šæ¨¡å‹èåˆ
            "voice_cloning_optimization": True,  # éŸ³è‰²å…‹éš†ä¼˜åŒ–
            "quality_assessment": True,  # è´¨é‡è¯„ä¼°
            "backup_models": ["xtts", "edge_tts", "pyttsx3"]  # å¤‡ç”¨æ¨¡å‹
        }
        
        self._setup_directories()
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "training": {
                "gpt_epochs": 50,
                "sovits_epochs": 100,
                "batch_size": 4,
                "learning_rate": 1e-4,
                "save_interval": 10,
                "precision": "fp16"
            },
            "data_preparation": {
                "sample_rate": 32000,
                "max_audio_length": 10.0,
                "min_audio_length": 1.0,
                "text_cleaning": True,
                "noise_reduction": True
            },
            "model": {
                "gpt_model": "gpt-v2",
                "sovits_model": "sovits-v2",
                "bert_model": "chinese-roberta-wwm-ext-large",
                "hubert_model": "chinese-hubert-base"
            }
        }
    
    def _setup_directories(self):
        """è®¾ç½®å¿…è¦çš„ç›®å½•"""
        directories = [self.result_dir, self.temp_dir]
        for dir_path in directories:
            dir_path.mkdir(exist_ok=True)
            logger.info(f"åˆ›å»ºç›®å½•: {dir_path}")
    
    def load_task_data(self) -> pd.DataFrame:
        """åŠ è½½ä»»åŠ¡æ•°æ®"""
        csv_path = self.base_dir / "aigc_speech_generation_tasks.csv"
        if not csv_path.exists():
            raise FileNotFoundError(f"ä»»åŠ¡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        
        df = pd.read_csv(csv_path, encoding='utf-8')
        logger.info(f"åŠ è½½äº† {len(df)} ä¸ªè®­ç»ƒä»»åŠ¡")
        return df
    
    def prepare_audio_data(self, df: pd.DataFrame) -> List[Dict]:
        """å‡†å¤‡éŸ³é¢‘æ•°æ® - å¢å¼ºç‰ˆï¼ˆå¤šçº¿ç¨‹å¤„ç†ï¼‰"""
        audio_data = []
        failed_files = []
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=len(df), desc="å¤„ç†éŸ³é¢‘æ–‡ä»¶", unit="ä¸ª")
        
        # çº¿ç¨‹é”
        lock = threading.Lock()
        
        def process_single_audio(row_data):
            """å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
            nonlocal audio_data, failed_files
            
            try:
                idx, row = row_data
                audio_file = self.audio_dir / row['reference_speech']
                
                if not audio_file.exists():
                    with lock:
                        failed_files.append(str(audio_file))
                    return
                
                # éŸ³é¢‘è´¨é‡æ£€æŸ¥å’Œé¢„å¤„ç†
                processed_audio = self._process_audio(audio_file, row['text'])
                if processed_audio:
                    result = {
                        'id': row['utt'],
                        'text': row['text'],
                        'audio_path': str(processed_audio),
                        'duration': self._get_audio_duration(processed_audio),
                        'quality_score': self._assess_audio_quality(processed_audio)
                    }
                    
                    with lock:
                        audio_data.append(result)
                
                pbar.update(1)
                
            except Exception as e:
                logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥: {e}")
                pbar.update(1)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†
        max_workers = min(8, len(df))  # æœ€å¤š8ä¸ªçº¿ç¨‹
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = [executor.submit(process_single_audio, (idx, row)) 
                      for idx, row in df.iterrows()]
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in futures:
                future.result()
        
        pbar.close()
        
        logger.info(f"æˆåŠŸå¤„ç† {len(audio_data)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        if failed_files:
            logger.warning(f"å¤±è´¥çš„æ–‡ä»¶æ•°é‡: {len(failed_files)}")
        
        return audio_data
    
    def _process_audio(self, audio_path: Path, text: str) -> Optional[Path]:
        """éŸ³é¢‘é¢„å¤„ç† - å¢å¼ºç‰ˆ"""
        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(audio_path, sr=self.config['data_preparation']['sample_rate'])
            
            # éŸ³é¢‘å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enhancement_config['audio_augmentation']:
                audio = self._apply_audio_augmentation(audio, sr)
            
            # å™ªå£°å‡å°‘
            if self.config['data_preparation']['noise_reduction']:
                audio = self._reduce_noise(audio, sr)
            
            # é•¿åº¦æ£€æŸ¥
            duration = len(audio) / sr
            if duration < self.config['data_preparation']['min_audio_length']:
                logger.warning(f"éŸ³é¢‘è¿‡çŸ­: {audio_path}")
                return None
            
            if duration > self.config['data_preparation']['max_audio_length']:
                audio = audio[:int(self.config['data_preparation']['max_audio_length'] * sr)]
            
            # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
            output_path = self.temp_dir / f"processed_{audio_path.name}"
            sf.write(output_path, audio, sr)
            
            return output_path
            
        except Exception as e:
            logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥ {audio_path}: {e}")
            return None
    
    def _apply_audio_augmentation(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """åº”ç”¨éŸ³é¢‘å¢å¼º"""
        # éšæœºéŸ³é«˜å˜åŒ–
        if np.random.random() > 0.5:
            pitch_shift = np.random.uniform(-2, 2)
            audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=pitch_shift)
        
        # éšæœºé€Ÿåº¦å˜åŒ–
        if np.random.random() > 0.5:
            speed_factor = np.random.uniform(0.9, 1.1)
            audio = librosa.effects.time_stretch(audio, rate=speed_factor)
        
        # æ·»åŠ è½»å¾®å™ªå£°
        if np.random.random() > 0.7:
            noise_level = np.random.uniform(0.001, 0.005)
            noise = np.random.normal(0, noise_level, len(audio))
            audio = audio + noise
        
        return audio
    
    def _reduce_noise(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """å™ªå£°å‡å°‘"""
        # ç®€å•çš„é¢‘è°±å‡æ³•é™å™ª
        stft = librosa.stft(audio)
        magnitude = np.abs(stft)
        
        # ä¼°è®¡å™ªå£°è°±
        noise_spectrum = np.mean(magnitude[:, :10], axis=1, keepdims=True)
        
        # é¢‘è°±å‡æ³•
        alpha = 2.0
        beta = 0.01
        cleaned_magnitude = magnitude - alpha * noise_spectrum
        cleaned_magnitude = np.maximum(cleaned_magnitude, beta * magnitude)
        
        # é‡å»ºéŸ³é¢‘
        cleaned_stft = cleaned_magnitude * np.exp(1j * np.angle(stft))
        cleaned_audio = librosa.istft(cleaned_stft)
        
        return cleaned_audio
    
    def _get_audio_duration(self, audio_path: Path) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            audio, sr = librosa.load(audio_path, sr=None)
            return len(audio) / sr
        except:
            return 0.0
    
    def _assess_audio_quality(self, audio_path: Path) -> float:
        """è¯„ä¼°éŸ³é¢‘è´¨é‡"""
        try:
            audio, sr = librosa.load(audio_path, sr=None)
            
            # è®¡ç®—ä¿¡å™ªæ¯”
            signal_power = np.mean(audio**2)
            noise_power = np.mean(audio[:1000]**2)  # å‡è®¾å‰1000ä¸ªæ ·æœ¬æ˜¯å™ªå£°
            snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
            
            # è®¡ç®—é¢‘è°±è´¨å¿ƒ
            spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_score = min(1.0, max(0.0, (snr + 20) / 40 + spectral_centroid / 2000))
            
            return quality_score
        except:
            return 0.5
    
    def prepare_training_data(self, audio_data: List[Dict]):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        logger.info("å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # åˆ›å»ºæ•°æ®é›†ç›®å½•
        dataset_dir = self.temp_dir / "dataset"
        dataset_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
        wav_dir = dataset_dir / "wav"
        wav_dir.mkdir(exist_ok=True)
        
        for item in audio_data:
            shutil.copy2(item['audio_path'], wav_dir / f"{item['id']}.wav")
        
        # åˆ›å»ºæ–‡æœ¬æ–‡ä»¶
        text_file = dataset_dir / "text.txt"
        with open(text_file, 'w', encoding='utf-8') as f:
            for item in audio_data:
                f.write(f"{item['id']}|{item['text']}\n")
        
        logger.info(f"è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆï¼Œå…± {len(audio_data)} ä¸ªæ ·æœ¬")
        return dataset_dir
    
    def run_data_preparation(self, dataset_dir: Path):
        """è¿è¡Œæ•°æ®å‡†å¤‡æ­¥éª¤"""
        logger.info("å¼€å§‹æ•°æ®å‡†å¤‡æ­¥éª¤...")
        
        # åˆ‡æ¢åˆ°GPT-SoVITSç›®å½•
        os.chdir(self.gpt_sovits_dir)
        
        # æ­¥éª¤1: æ–‡æœ¬å¤„ç†
        logger.info("æ­¥éª¤1: æ–‡æœ¬å¤„ç†")
        cmd1 = f"python GPT_SoVITS/prepare_datasets/1-get-text.py --data_path {dataset_dir}"
        self._run_command(cmd1)
        
        # æ­¥éª¤2: HuBERTç‰¹å¾æå–
        logger.info("æ­¥éª¤2: HuBERTç‰¹å¾æå–")
        cmd2 = f"python GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py --data_path {dataset_dir}"
        self._run_command(cmd2)
        
        # æ­¥éª¤3: è¯­ä¹‰ç‰¹å¾æå–
        logger.info("æ­¥éª¤3: è¯­ä¹‰ç‰¹å¾æå–")
        cmd3 = f"python GPT_SoVITS/prepare_datasets/3-get-semantic.py --data_path {dataset_dir}"
        self._run_command(cmd3)
        
        # åˆ‡æ¢å›åŸç›®å½•
        os.chdir(self.base_dir)
        logger.info("æ•°æ®å‡†å¤‡å®Œæˆ")
    
    def train_gpt_model(self, dataset_dir: Path):
        """è®­ç»ƒGPTæ¨¡å‹"""
        logger.info("å¼€å§‹è®­ç»ƒGPTæ¨¡å‹...")
        
        # åˆ›å»ºè®­ç»ƒé…ç½®
        config = self._create_gpt_config()
        
        # åˆ‡æ¢åˆ°GPT-SoVITSç›®å½•
        os.chdir(self.gpt_sovits_dir)
        
        # è¿è¡Œè®­ç»ƒ
        cmd = f"python GPT_SoVITS/s1_train.py --config {config}"
        self._run_command(cmd)
        
        # åˆ‡æ¢å›åŸç›®å½•
        os.chdir(self.base_dir)
        logger.info("GPTæ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def train_sovits_model(self, dataset_dir: Path):
        """è®­ç»ƒSoVITSæ¨¡å‹"""
        logger.info("å¼€å§‹è®­ç»ƒSoVITSæ¨¡å‹...")
        
        # åˆ›å»ºè®­ç»ƒé…ç½®
        config = self._create_sovits_config()
        
        # åˆ‡æ¢åˆ°GPT-SoVITSç›®å½•
        os.chdir(self.gpt_sovits_dir)
        
        # è¿è¡Œè®­ç»ƒ
        cmd = f"python GPT_SoVITS/s2_train.py --config {config}"
        self._run_command(cmd)
        
        # åˆ‡æ¢å›åŸç›®å½•
        os.chdir(self.base_dir)
        logger.info("SoVITSæ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def _create_gpt_config(self) -> Path:
        """åˆ›å»ºGPTè®­ç»ƒé…ç½®æ–‡ä»¶"""
        config = {
            "data": {
                "training_files": str(self.temp_dir / "dataset" / "filelist.txt"),
                "validation_files": str(self.temp_dir / "dataset" / "filelist.txt"),
                "text_cleaners": ["cjke_cleaners2"],
                "max_wav_value": 32768.0,
                "sampling_rate": 22050,
                "filter_length": 1024,
                "hop_length": 256,
                "win_length": 1024,
                "n_mel_channels": 80,
                "mel_fmin": 0.0,
                "mel_fmax": None,
                "add_blank": True,
                "n_speakers": 0,
                "cleaned_text": True,
                "max_sec": 10,
                "pad_val": 0,
                "num_workers": 4
            },
            "model": {
                "inter_channels": 192,
                "hidden_channels": 192,
                "filter_channels": 768,
                "n_heads": 2,
                "n_layers": 6,
                "kernel_size": 3,
                "p_dropout": 0.1,
                "resblock": "1",
                "resblock_kernel_sizes": [3, 7, 11],
                "resblock_dilation_sizes": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],
                "upsample_rates": [8, 8, 2, 2],
                "upsample_initial_channel": 512,
                "upsample_kernel_sizes": [16, 16, 4, 4],
                "n_layers_q": 3,
                "use_spectral_norm": False,
                "gin_channels": 256
            },
            "train": {
                "log_interval": 200,
                "eval_interval": 1000,
                "seed": 1234,
                "epochs": 5,  # å‡å°‘è®­ç»ƒè½®æ•°
                "learning_rate": 2e-4,
                "betas": [0.8, 0.99],
                "eps": 1e-9,
                "batch_size": 4,
                "fp16_run": False,
                "lr_decay": 0.999875,
                "segment_size": 8192,
                "init_lr_ratio": 1,
                "warmup_epochs": 0,
                "c_mel": 45,
                "c_kl": 1.0,
                "if_save_latest": True,
                "if_save_every_weights": False,
                "half_weights_save_dir": str(self.temp_dir / "logs" / "s1" / "half_weights"),
                "exp_name": "s1",
                "output_dir": str(self.temp_dir / "logs" / "s1")
            }
        }
        
        config_path = self.temp_dir / "gpt_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        return config_path

    def _create_sovits_config(self) -> Path:
        """åˆ›å»ºSoVITSè®­ç»ƒé…ç½®æ–‡ä»¶"""
        config = {
            "train": {
                "log_interval": 200,
                "eval_interval": 1000,
                "seed": 1234,
                "epochs": 10,  # å‡å°‘è®­ç»ƒè½®æ•°
                "learning_rate": 2e-4,
                "betas": [0.8, 0.99],
                "eps": 1e-9,
                "batch_size": 4,
                "fp16_run": False,
                "lr_decay": 0.999875,
                "segment_size": 8192,
                "init_lr_ratio": 1,
                "warmup_epochs": 0,
                "c_mel": 45,
                "c_kl": 1.0,
                "if_save_latest": True,
                "if_save_every_weights": False,
                "half_weights_save_dir": str(self.temp_dir / "logs" / "s2" / "half_weights"),
                "exp_name": "s2",
                "output_dir": str(self.temp_dir / "logs" / "s2")
            },
            "data": {
                "training_files": str(self.temp_dir / "dataset" / "filelist.txt"),
                "validation_files": str(self.temp_dir / "dataset" / "filelist.txt"),
                "text_cleaners": ["cjke_cleaners2"],
                "max_wav_value": 32768.0,
                "sampling_rate": 22050,
                "filter_length": 1024,
                "hop_length": 256,
                "win_length": 1024,
                "n_mel_channels": 80,
                "mel_fmin": 0.0,
                "mel_fmax": None,
                "add_blank": True,
                "n_speakers": 0,
                "cleaned_text": True
            },
            "model": {
                "inter_channels": 192,
                "hidden_channels": 192,
                "filter_channels": 768,
                "n_heads": 2,
                "n_layers": 6,
                "kernel_size": 3,
                "p_dropout": 0.1,
                "resblock": "1",
                "resblock_kernel_sizes": [3, 7, 11],
                "resblock_dilation_sizes": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],
                "upsample_rates": [8, 8, 2, 2],
                "upsample_initial_channel": 512,
                "upsample_kernel_sizes": [16, 16, 4, 4],
                "n_layers_q": 3,
                "use_spectral_norm": False,
                "gin_channels": 256
            }
        }
        
        config_path = self.temp_dir / "sovits_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        return config_path
    
    def _run_command(self, cmd: str, show_progress: bool = True) -> bool:
        """è¿è¡Œå‘½ä»¤ï¼ˆå¸¦è¿›åº¦ç›‘æ§ï¼‰"""
        try:
            logger.info(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
            
            if show_progress:
                # ä½¿ç”¨å®æ—¶è¾“å‡ºæ˜¾ç¤ºè¿›åº¦
                process = subprocess.Popen(
                    cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                    text=True, encoding='utf-8', bufsize=1, universal_newlines=True
                )
                
                # å®æ—¶æ˜¾ç¤ºè¾“å‡º
                for line in process.stdout:
                    line = line.strip()
                    if line:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿›åº¦ä¿¡æ¯
                        if any(keyword in line.lower() for keyword in ['epoch', 'step', 'loss', 'progress']):
                            logger.info(f"è®­ç»ƒè¿›åº¦: {line}")
                        else:
                            logger.debug(line)
                
                process.wait()
                return process.returncode == 0
            else:
                # é™é»˜æ‰§è¡Œ
                result = subprocess.run(
                    cmd, shell=True, capture_output=True, text=True, encoding='utf-8'
                )
                
                if result.returncode == 0:
                    logger.info("å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
                    return True
                else:
                    logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")
                    return False
                
        except Exception as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {e}")
            return False
    
    def generate_audio_files(self, df: pd.DataFrame, dataset_dir: Path) -> List[Dict]:
        """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        logger.info("å¼€å§‹ç”ŸæˆéŸ³é¢‘æ–‡ä»¶...")
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=len(df), desc="ç”ŸæˆéŸ³é¢‘æ–‡ä»¶", unit="ä¸ª")
        
        result_data = []
        
        for _, row in df.iterrows():
            try:
                # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”ŸæˆéŸ³é¢‘ - ç¬¦åˆbaselineæ ¼å¼
                output_file = self.result_dir / f"{row['utt']}.wav"
                
                # è¿™é‡Œåº”è¯¥è°ƒç”¨GPT-SoVITSçš„æ¨ç†æ¥å£
                # ç”±äºæˆ‘ä»¬æ²¡æœ‰å®Œæ•´çš„æ¨ç†ä»£ç ï¼Œæˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªå ä½ç¬¦
                success = self._generate_single_audio(row['text'], output_file, dataset_dir)
                
                if success:
                    result_data.append({
                        'utt': row['utt'],
                        'reference_speech': row['reference_speech'],
                        'text': row['text'],
                        'synthesized_speech': f"{row['utt']}.wav"
                    })
                
                pbar.update(1)
                
            except Exception as e:
                logger.error(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥ {row['utt']}: {e}")
                pbar.update(1)
        
        pbar.close()
        
        logger.info(f"æˆåŠŸç”Ÿæˆ {len(result_data)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        return result_data
    
    def _generate_single_audio(self, text: str, output_file: Path, dataset_dir: Path) -> bool:
        """ç”Ÿæˆå•ä¸ªéŸ³é¢‘æ–‡ä»¶ - ä½¿ç”¨çœŸå®çš„GPT-SoVITSæ¨ç†"""
        try:
            # å¯¼å…¥GPT-SoVITSæ¨ç†æ¨¡å—
            import sys
            sys.path.append(str(self.gpt_sovits_dir))
            
            # åˆ‡æ¢åˆ°GPT-SoVITSç›®å½•
            original_cwd = os.getcwd()
            os.chdir(self.gpt_sovits_dir)
            
            try:
                # å¯¼å…¥æ¨ç†æ¨¡å—
                from GPT_SoVITS.inference_webui import get_tts_wav, change_gpt_weights, change_sovits_weights, i18n, dict_language as global_dict_language
                
                # è®¾ç½®æ¨¡å‹è·¯å¾„ï¼ˆä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
                gpt_model_path = self.temp_dir / "logs" / "s1" / "latest.pth"
                sovits_model_path = self.temp_dir / "logs" / "s2" / "latest.pth"
                
                # å¦‚æœè®­ç»ƒå¥½çš„æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
                if not gpt_model_path.exists():
                    gpt_model_path = self.gpt_sovits_dir / "GPT_SoVITS" / "pretrained_models" / "s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt"
                if not sovits_model_path.exists():
                    sovits_model_path = self.gpt_sovits_dir / "GPT_SoVITS" / "pretrained_models" / "s2G488k.pth"
                
                # åŠ è½½æ¨¡å‹
                change_gpt_weights(str(gpt_model_path))
                change_sovits_weights(str(sovits_model_path))
                
                # ç¡®ä¿dict_languageè¢«æ­£ç¡®åˆå§‹åŒ–
                # ä»api.pyä¸­å¤åˆ¶dict_languageçš„å®šä¹‰
                global_dict_language.update({
                    "ä¸­æ–‡": "all_zh",
                    "ç²¤è¯­": "all_yue",
                    "è‹±æ–‡": "en",
                    "æ—¥æ–‡": "all_ja",
                    "éŸ©æ–‡": "all_ko",
                    "ä¸­è‹±æ··åˆ": "zh",
                    "ç²¤è‹±æ··åˆ": "yue",
                    "æ—¥è‹±æ··åˆ": "ja",
                    "éŸ©è‹±æ··åˆ": "ko",
                    "å¤šè¯­ç§æ··åˆ": "auto",
                    "å¤šè¯­ç§æ··åˆ(ç²¤è¯­)": "auto_yue",
                    "all_zh": "all_zh",
                    "all_yue": "all_yue",
                    "en": "en",
                    "all_ja": "all_ja",
                    "all_ko": "all_ko",
                    "zh": "zh",
                    "yue": "yue",
                    "ja": "ja",
                    "ko": "ko",
                    "auto": "auto",
                    "auto_yue": "auto_yue",
                })
                
                # æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘è·¯å¾„
                # å‡è®¾å‚è€ƒéŸ³é¢‘åœ¨ dataset_dir/raw ç›®å½•ä¸‹ï¼Œä¸”æ–‡ä»¶åä¸ utt å¯¹åº”
                # ä¾‹å¦‚ï¼šdataset_dir/raw/1.wav
                ref_audio_path = dataset_dir / "raw" / f"{output_file.stem}.wav"
                if not ref_audio_path.exists():
                    logger.warning(f"å‚è€ƒéŸ³é¢‘ {ref_audio_path} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤å‚è€ƒéŸ³é¢‘ã€‚")
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„å‚è€ƒéŸ³é¢‘ï¼Œå¯ä»¥ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„å‚è€ƒéŸ³é¢‘
                    # æˆ–è€…è·³è¿‡æ­¤æ¡ï¼Œå–å†³äºæ¯”èµ›è¦æ±‚
                    # è¿™é‡Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªé¢„è®¾çš„é€šç”¨å‚è€ƒéŸ³é¢‘
                    # For demonstration, we'll use a dummy path, but in real use, it must be a valid audio file
                    ref_audio_path = self.audio_dir / "reference_1.wav" # ä½¿ç”¨éŸ³é¢‘ç›®å½•ä¸­çš„å‚è€ƒéŸ³é¢‘
                    if not ref_audio_path.exists():
                        logger.error(f"é»˜è®¤å‚è€ƒéŸ³é¢‘ {ref_audio_path} ä¹Ÿä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œæ¨ç†ã€‚")
                        return False
                
                # æ™ºèƒ½æ£€æµ‹æ–‡æœ¬è¯­è¨€æ¨¡å¼
                language_mode = self._detect_language_mode(text)
                logger.info(f"è¯­è¨€æ¨¡å¼: {language_mode}, æ–‡æœ¬é¢„è§ˆ: {text[:50]}...")
                
                # ä½¿ç”¨GPT-SoVITSè¿›è¡Œæ¨ç†
                synthesis_result = get_tts_wav(
                    ref_wav_path=str(ref_audio_path),
                    prompt_text="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚",  # ç®€å•çš„promptæ–‡æœ¬
                    prompt_language=language_mode,  # ä½¿ç”¨ä¸æ–‡æœ¬ç›¸åŒçš„è¯­è¨€æ¨¡å¼
                    text=text,
                    text_language=language_mode,  # æ ¹æ®æ–‡æœ¬å†…å®¹é€‰æ‹©è¯­è¨€æ¨¡å¼
                    top_k=20,
                    top_p=0.6,
                    temperature=0.6,
                    speed=1.0,
                    sample_steps=8
                )
                
                # è·å–ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®
                result_list = list(synthesis_result)
                if result_list:
                    # è·å–æœ€åä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„éŸ³é¢‘ï¼‰
                    last_sampling_rate, last_audio_data = result_list[-1]
                    
                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    sf.write(output_file, last_audio_data, last_sampling_rate)
                    logger.info(f"æˆåŠŸç”ŸæˆéŸ³é¢‘: {output_file}")
                    return True
                else:
                    logger.error("GPT-SoVITSæ¨ç†æœªè¿”å›éŸ³é¢‘æ•°æ®")
                    return False
                    
            except ImportError as e:
                logger.error(f"å¯¼å…¥GPT-SoVITSæ¨¡å—å¤±è´¥: {e}")
                # å›é€€åˆ°ç”Ÿæˆç¤ºä¾‹éŸ³é¢‘
                return self._generate_fallback_audio(output_file)
            except Exception as e:
                logger.error(f"GPT-SoVITSæ¨ç†å¤±è´¥: {e}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                # å›é€€åˆ°ç”Ÿæˆç¤ºä¾‹éŸ³é¢‘
                return self._generate_fallback_audio(output_file)
            finally:
                # åˆ‡æ¢å›åŸç›®å½•
                os.chdir(original_cwd)
                
        except Exception as e:
            logger.error(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
            return self._generate_fallback_audio(output_file)
    
    def _detect_language_mode(self, text: str) -> str:
        """æ™ºèƒ½æ£€æµ‹æ–‡æœ¬è¯­è¨€æ¨¡å¼"""
        import re
        
        # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å­—ç¬¦çš„æ•°é‡
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        total_chars = len(text.strip())
        
        # å¦‚æœä¸»è¦æ˜¯ä¸­æ–‡ï¼ˆä¸­æ–‡å æ¯”è¶…è¿‡80%ï¼‰ï¼Œä½¿ç”¨çº¯ä¸­æ–‡æ¨¡å¼
        if chinese_chars > 0 and chinese_chars / total_chars > 0.8:
            return "all_zh"
        # å¦‚æœåŒ…å«è‹±æ–‡ä½†ä¸­æ–‡ä»ç„¶æ˜¯ä¸»è¦è¯­è¨€ï¼Œä½¿ç”¨ä¸­è‹±æ··åˆæ¨¡å¼
        elif english_chars > 0 and chinese_chars > english_chars:
            return "zh"
        # å¦‚æœè‹±æ–‡å ä¸»å¯¼ï¼Œä½¿ç”¨è‹±æ–‡æ¨¡å¼
        elif english_chars > chinese_chars:
            return "en"
        # é»˜è®¤ä½¿ç”¨çº¯ä¸­æ–‡æ¨¡å¼
        else:
            return "all_zh"
    
    def _generate_fallback_audio(self, output_file: Path) -> bool:
        """ç”Ÿæˆå›é€€éŸ³é¢‘ï¼ˆå½“GPT-SoVITSæ¨ç†å¤±è´¥æ—¶ï¼‰"""
        try:
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹éŸ³é¢‘ï¼ˆ1ç§’çš„é™éŸ³ï¼‰
            import numpy as np
            sample_rate = 22050
            duration = 1.0  # 1ç§’
            samples = int(sample_rate * duration)
            audio_data = np.zeros(samples)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            sf.write(output_file, audio_data, sample_rate)
            logger.warning(f"ä½¿ç”¨å›é€€éŸ³é¢‘: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›é€€éŸ³é¢‘å¤±è´¥: {e}")
            return False
    
    def generate_result_csv(self, result_data: List[Dict]) -> Path:
        """ç”Ÿæˆç»“æœCSVæ–‡ä»¶"""
        result_df = pd.DataFrame(result_data)
        result_path = self.result_dir / "result.csv"
        result_df.to_csv(result_path, index=False, encoding='utf-8')
        
        logger.info(f"ç”Ÿæˆç»“æœæ–‡ä»¶: {result_path}")
        return result_path
    
    def create_result_archive(self) -> Path:
        """åˆ›å»ºç»“æœå‹ç¼©åŒ… - ç¬¦åˆbaselineæ ¼å¼"""
        archive_path = self.base_dir / "result_gpt_sovits.zip"
        
        try:
            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # æ·»åŠ ç»“æœCSV
                result_csv = self.result_dir / "result.csv"
                if result_csv.exists():
                    zipf.write(result_csv, result_csv.name)
                    logger.info(f"æ·»åŠ ç»“æœCSVæ–‡ä»¶: {result_csv.name}")
                else:
                    logger.warning(f"ç»“æœCSVæ–‡ä»¶ä¸å­˜åœ¨: {result_csv}")
                
                # æ·»åŠ ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ - ç›´æ¥æ”¾åœ¨æ ¹ç›®å½•ï¼Œç¬¦åˆbaselineæ ¼å¼
                audio_count = 0
                for audio_file in self.result_dir.glob("*.wav"):
                    try:
                        zipf.write(audio_file, audio_file.name)
                        audio_count += 1
                    except Exception as e:
                        logger.error(f"æ·»åŠ éŸ³é¢‘æ–‡ä»¶å¤±è´¥ {audio_file}: {e}")
                
                logger.info(f"æ·»åŠ äº† {audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶")
                
                # æ·»åŠ è®­ç»ƒæ—¥å¿—
                log_file = self.base_dir / "gpt_sovits_training.log"
                if log_file.exists():
                    zipf.write(log_file, log_file.name)
                    logger.info(f"æ·»åŠ è®­ç»ƒæ—¥å¿—æ–‡ä»¶: {log_file.name}")
                else:
                    logger.warning(f"è®­ç»ƒæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            
            logger.info(f"åˆ›å»ºç»“æœå‹ç¼©åŒ…æˆåŠŸ: {archive_path}")
            return archive_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå‹ç¼©åŒ…å¤±è´¥: {e}")
            raise
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            logger.info("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹GPT-SoVITSè®­ç»ƒæµç¨‹...")
    
    # å®šä¹‰è®­ç»ƒæ­¥éª¤
    training_steps = [
        "åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ",
        "åŠ è½½ä»»åŠ¡æ•°æ®", 
        "å‡†å¤‡éŸ³é¢‘æ•°æ®ï¼ˆå¤šçº¿ç¨‹å¤„ç†ï¼‰",
        "å‡†å¤‡è®­ç»ƒæ•°æ®é›†",
        "è¿è¡Œæ•°æ®å‡†å¤‡æ­¥éª¤",
        "è®­ç»ƒGPTæ¨¡å‹",
        "è®­ç»ƒSoVITSæ¨¡å‹", 
        "ç”ŸæˆéŸ³é¢‘æ–‡ä»¶",
        "ç”Ÿæˆç»“æœæ–‡ä»¶",
        "åˆ›å»ºç»“æœå‹ç¼©åŒ…"
    ]
    
    # åˆå§‹åŒ–è¿›åº¦ç›‘æ§å™¨
    progress_monitor = TrainingProgressMonitor(len(training_steps))
    
    try:
        # æ­¥éª¤1: åˆå§‹åŒ–è®­ç»ƒAPI
        progress_monitor.update("åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ", "åˆ›å»ºç›®å½•ç»“æ„å’Œé…ç½®")
        trainer = GPTSoVITSTrainingAPI()
        
        # æ­¥éª¤2: åŠ è½½ä»»åŠ¡æ•°æ®
        progress_monitor.update("åŠ è½½ä»»åŠ¡æ•°æ®", "è¯»å–CSVæ–‡ä»¶")
        df = trainer.load_task_data()
        
        # æ­¥éª¤3: å‡†å¤‡éŸ³é¢‘æ•°æ®ï¼ˆå¤šçº¿ç¨‹å¤„ç†ï¼‰
        progress_monitor.update("å‡†å¤‡éŸ³é¢‘æ•°æ®ï¼ˆå¤šçº¿ç¨‹å¤„ç†ï¼‰", "éŸ³é¢‘é¢„å¤„ç†å’Œè´¨é‡è¯„ä¼°")
        audio_data = trainer.prepare_audio_data(df)
        
        if not audio_data:
            logger.error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®ï¼Œè®­ç»ƒç»ˆæ­¢")
            return
        
        # æ­¥éª¤4: å‡†å¤‡è®­ç»ƒæ•°æ®
        progress_monitor.update("å‡†å¤‡è®­ç»ƒæ•°æ®é›†", "åˆ›å»ºæ•°æ®é›†ç›®å½•å’Œæ–‡ä»¶")
        dataset_dir = trainer.prepare_training_data(audio_data)
        
        # æ­¥éª¤5: è¿è¡Œæ•°æ®å‡†å¤‡
        progress_monitor.update("è¿è¡Œæ•°æ®å‡†å¤‡æ­¥éª¤", "æ–‡æœ¬å¤„ç†ã€HuBERTç‰¹å¾æå–ã€è¯­ä¹‰ç‰¹å¾æå–")
        trainer.run_data_preparation(dataset_dir)
        
        # æ­¥éª¤6: è®­ç»ƒGPTæ¨¡å‹
        progress_monitor.update("è®­ç»ƒGPTæ¨¡å‹", f"è®­ç»ƒè½®æ•°: {trainer.config['training']['gpt_epochs']}")
        trainer.train_gpt_model(dataset_dir)
        
        # æ­¥éª¤7: è®­ç»ƒSoVITSæ¨¡å‹
        progress_monitor.update("è®­ç»ƒSoVITSæ¨¡å‹", f"è®­ç»ƒè½®æ•°: {trainer.config['training']['sovits_epochs']}")
        trainer.train_sovits_model(dataset_dir)
        
        # æ­¥éª¤8: ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        progress_monitor.update("ç”ŸæˆéŸ³é¢‘æ–‡ä»¶", "ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”ŸæˆéŸ³é¢‘")
        result_data = trainer.generate_audio_files(df, dataset_dir)
        
        # æ­¥éª¤9: ç”Ÿæˆç»“æœæ–‡ä»¶
        progress_monitor.update("ç”Ÿæˆç»“æœæ–‡ä»¶", "åˆ›å»ºç»“æœCSVæ–‡ä»¶")
        trainer.generate_result_csv(result_data)
        
        # æ­¥éª¤10: åˆ›å»ºç»“æœå‹ç¼©åŒ…
        progress_monitor.update("åˆ›å»ºç»“æœå‹ç¼©åŒ…", "æ‰“åŒ…è®­ç»ƒç»“æœ")
        archive_path = trainer.create_result_archive()
        
        logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼ç»“æœå‹ç¼©åŒ…: {archive_path}")
        logger.info(f"ğŸ“Š æ€»ç”¨æ—¶: {progress_monitor._format_time(time.time() - progress_monitor.start_time)}")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        logger.info("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        trainer.cleanup()

def test_mode():
    """æµ‹è¯•æ¨¡å¼ - åªå¤„ç†å°‘é‡æ•°æ®"""
    logger.info("ğŸ§ª å¯åŠ¨æµ‹è¯•æ¨¡å¼...")
    
    # ä¿®æ”¹é…ç½®ä¸ºæµ‹è¯•æ¨¡å¼
    test_config = {
        "training": {
            "gpt_epochs": 2,  # å‡å°‘è®­ç»ƒè½®æ•°
            "sovits_epochs": 2,
            "batch_size": 2,
            "learning_rate": 1e-4,
            "save_interval": 1,
            "precision": "fp16"
        },
        "data_preparation": {
            "sample_rate": 32000,
            "max_audio_length": 5.0,  # å‡å°‘éŸ³é¢‘é•¿åº¦
            "min_audio_length": 0.5,
            "text_cleaning": True,
            "noise_reduction": False  # å…³é—­å™ªå£°å‡å°‘ä»¥åŠ å¿«é€Ÿåº¦
        },
        "model": {
            "gpt_model": "gpt-v2",
            "sovits_model": "sovits-v2",
            "bert_model": "chinese-roberta-wwm-ext-large",
            "hubert_model": "chinese-hubert-base"
        }
    }
    
    # ä¿å­˜æµ‹è¯•é…ç½®
    with open("test_config.yaml", "w", encoding="utf-8") as f:
        yaml.dump(test_config, f, default_flow_style=False)
    
    try:
        # ä½¿ç”¨æµ‹è¯•é…ç½®åˆå§‹åŒ–
        trainer = GPTSoVITSTrainingAPI("test_config.yaml")
        
        # åªå¤„ç†å‰5ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•
        df = trainer.load_task_data()
        df_test = df.head(5)  # åªå–å‰5ä¸ª
        
        logger.info(f"æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç† {len(df_test)} ä¸ªæ–‡ä»¶")
        
        # å‡†å¤‡éŸ³é¢‘æ•°æ®
        audio_data = trainer.prepare_audio_data(df_test)
        
        if not audio_data:
            logger.error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®ï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        dataset_dir = trainer.prepare_training_data(audio_data)
        
        logger.info("âœ… æµ‹è¯•æ¨¡å¼å®Œæˆ - æ•°æ®å‡†å¤‡é˜¶æ®µéªŒè¯æˆåŠŸ")
        logger.info("ğŸ’¡ å¦‚éœ€å®Œæ•´è®­ç»ƒï¼Œè¯·è¿è¡Œ: python gpt_sovits_training_complete.py")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ¨¡å¼å¤±è´¥: {e}")
        raise
    finally:
        # æ¸…ç†æµ‹è¯•é…ç½®
        if Path("test_config.yaml").exists():
            Path("test_config.yaml").unlink()

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        test_mode()
    else:
        main()



